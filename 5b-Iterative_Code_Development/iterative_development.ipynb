{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top\" id=\"top\"></a>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <h1>CHE597 - Iterative Development</h1>\n",
    "    <a href=\"https://github.com/bernalde\">David E. Bernal Neira</a>\n",
    "    <br>\n",
    "    <i>Davidson School of Chemical Engineering, Purdue University</i>\n",
    "    <br>\n",
    "    <a href=\"https://colab.research.google.com/github/SECQUOIA/PU_CHE597_S2025/blob/main/5b-Iterative_Code_Development/iterative_development.ipynb\" target=\"_parent\">\n",
    "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "    </a>\n",
    "    <a href=\"https://secquoia.github.io/\">\n",
    "        <img src=\"https://img.shields.io/badge/🌲⚛️🌐-SECQUOIA-blue\" alt=\"SECQUOIA\"/>\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hwuu8MHfbJyP",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19645,
     "status": "ok",
     "timestamp": 1581786857511,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "ROilA-3fbg8B",
    "outputId": "ea3d5f33-b5ff-4790-cfb1-fe35414ea35a"
   },
   "outputs": [],
   "source": [
    "# If using this on Google colab, we need to install the packages\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x85mz3FCbJyR"
   },
   "source": [
    "<b>If you are using google colab you should save this notebook and any associated textfiles to their own folder on your google drive. Then you will need to adapt the following commands so that the notebook runs from the location of that folder.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use Google Drive to save/load files, set this to True\n",
    "USE_GOOGLE_DRIVE = False\n",
    "if IN_COLAB and USE_GOOGLE_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Colab command to navigate to the folder holding the homework,\n",
    "    # CHANGE FOR YOUR SPECIFIC FOLDER LOCATION IN GOOGLE DRIVE\n",
    "    # Note: if there are spaces in the path, you need to precede them with a backslash '\\'\n",
    "    %cd /content/drive/My\\ Drive/CHE597/In-Class_Examples/HW2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHuyVjoYfnMB"
   },
   "source": [
    "# Iterative Development\n",
    "\n",
    "When you are writing complex programs, or even just multi-step functions or loops, it is critical that you break things into digestible chunks. The term <b>iterative development</b> describes this necessity to iterate on a piece of code, until it does everything you want. \n",
    "\n",
    "On HW 2, I asked you to write two functions that required several steps each: writing a window average function, and writing a parser for a file with chained data for multiple reactors. In each of these problems you had to write functions that did several things at once. But starting from scratch, it is very difficult to write something that does everything on the first try. It is much easier to write pieces of the functions, test as you go, and incrementally build up the coding solution. In this notebook, I will show you an example of how iterative development works. \n",
    "\n",
    "Here is the `multi_reactor.txt` parsing problem from the homework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeIfVJ-V00eP"
   },
   "outputs": [],
   "source": [
    "# The file mult_reactors.txt have time vs impurity data for several reactors\n",
    "# Inspect the file.\n",
    "# Write your own parser that reads each reactor's data into a separate array\n",
    "# and assigns these arrays to a dictionary with pointer reactors.\n",
    "# NOTE: np.genfromtxt() and np.loadtxt() will not work for this task\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZeP8bH-1apX"
   },
   "source": [
    "This problems asks us to 1) open a file for reading and iteration, 2) distinguish between different reactors, and 3) save the data is a specific format (arrays within a dictionary).\n",
    "\n",
    "Taking an iterative approach we will break this down into elementary tasks. Specifically, we will start with reading data, then just try and parse the first reactor's data, before finally trying to parse all of the reactors at once. Eventually we will arrive at a relatively sophisticated solution, but each of the individual steps are quite straightforward.  \n",
    "\n",
    " Let's first write a solution for opening the file and iterating over its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1581787028822,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "F12jmyX100et",
    "outputId": "493c1ebe-5434-42ab-b9cc-be00da2920d4"
   },
   "outputs": [],
   "source": [
    "with open(\"mult_reactors.txt\",'r') as f:\n",
    "  for count, lines in enumerate(f):\n",
    "    print(lines)\n",
    "\n",
    "    # For diagnostic purposes\n",
    "    if count == 10:\n",
    "      break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4ZJZo292GYa"
   },
   "source": [
    "The code above is responsible for opening the file and reading it line by line. We've also used the `count/enumerate` construction to test it on the first few lines. We won't keep this around in the final solution, but putting in this kind of diagnostic scaffolding is important while we're developing our solution. Now, let's add code so that we only get the parts of the file that are data (as opposed to all of the strings and headers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1581787285848,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "OzWDolQ53Gpy",
    "outputId": "927e01c4-0fbd-44de-b4fa-86963d719ee3"
   },
   "outputs": [],
   "source": [
    "with open(\"mult_reactors.txt\",'r') as f:\n",
    "  for count, lines in enumerate(f):\n",
    "    fields = lines.split() # the file is space delimitted so this breaks up the lines into words\n",
    "\n",
    "    # Get the numbers\n",
    "    try:\n",
    "      print(\"{} {}\".format(float(fields[0]),float(fields[1]))) # only numbers will survive this try\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    # For diagnostic purposes\n",
    "    if count == 10:\n",
    "      break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhiRetYs3pZ-"
   },
   "source": [
    "So far so good, we are (1) reading the file and (2) only grabbing the data. Now, we want to save the data, not just print it. Since we are reading in line by line, we will need to use an object that is good for appending values, like a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1581787461417,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "Ajwy7d0C4DOy",
    "outputId": "314c57da-714c-4a89-88cb-c498a4f0cb41"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"mult_reactors.txt\",'r') as f:\n",
    "  for count, lines in enumerate(f):\n",
    "    fields = lines.split() # the file is space delimitted so this breaks up the lines into words\n",
    "\n",
    "    # Get the numbers\n",
    "    try:\n",
    "      data += [float(fields[0]),float(fields[1])]\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    # For diagnostic purposes\n",
    "    if count == 10:\n",
    "      break \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBkAQ6mo4VAx"
   },
   "source": [
    "Now we are saving the data, but we can see a problem: it isn't keeping the rows separate in the list, it is just combining all of the rows. To keep the rows separate, it is better to save the data as a list of lists, or list of tupels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1581787557053,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "y1Ef8UJT4nu9",
    "outputId": "082f1ec7-6fca-4859-f551-2bfe8c53f992"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"mult_reactors.txt\",'r') as f:\n",
    "  for count, lines in enumerate(f):\n",
    "    fields = lines.split() # the file is space delimitted so this breaks up the lines into words\n",
    "\n",
    "    # Get the numbers\n",
    "    try:\n",
    "      data += [[float(fields[0]),float(fields[1])]]\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    # For diagnostic purposes\n",
    "    if count == 10:\n",
    "      break \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31ZmxK0M4tAG"
   },
   "source": [
    "Now, the data from row `0` is in the list at index `0`, and so on. \n",
    "\n",
    "Next we know that there are several indpendent reactors. Each separated by a header. Let's add the code necessary to <b>only get the data from the first reactor</b>. This is a good interative strategy. After we get the first reactor working, we can deal with the other reactors.\n",
    "\n",
    "To only get the first reactor's data we will add a \"counter\" or \"iteration\" variable `N_reactor`, to keep track of which reactor we are parsing, and we will need to add an `if` statment of some kind to figure out when the reactor's data ends. We will also update our `break` statement to exit the loop after we think that we have the first reactor's data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 310,
     "status": "error",
     "timestamp": 1581791954659,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "P3J15F995GA8",
    "outputId": "f1ced0f5-33c2-4bc5-85d4-81835198f050"
   },
   "outputs": [],
   "source": [
    "data = [] # will temporarily hold each reactor's data\n",
    "N_reactor = -1 # keeps track of which reactor we are parsing\n",
    "with open(\"mult_reactors.txt\",'r') as f:\n",
    "  for lines in f:\n",
    "    fields = lines.split() # the file is space delimitted so this breaks up the lines into words\n",
    "\n",
    "    # Identify start of new reactor data \n",
    "    if fields[0] == \"Time(min)\":\n",
    "      N_reactor += 1\n",
    "\n",
    "    # Get the numbers\n",
    "    try:\n",
    "      data += [[float(fields[0]),float(fields[1])]]\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    # For diagnostic purposes\n",
    "    if N_reactor == 1:\n",
    "      break\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dfPCy_zs5wvu"
   },
   "source": [
    "We've added a way of finding the end of the reactor's data by using the header entry `\"Time(min)\"`. Every time that the parser encounters such a line, a new reactor is about to be parsed. We've also updated our diagnostic `break` statement to break after the first reactor has been parsed (i.e., when `N_reactor == 1`) and we've removed the `enumerate()` function because it isn't needed any longer.\n",
    "\n",
    "However, we've encountered a problem: `IndexError: list index out of range`. This means that we've tried to access an element `fields[0]` which is out of range for the list. Since `0` is the first element, this means that during this iteration the list was empty. Let's add a `print` statement to see what was happening right before the failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 301,
     "status": "error",
     "timestamp": 1581791971132,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "-njO4ny56k6K",
    "outputId": "0d99e747-0772-480f-ecd6-998309b23448"
   },
   "outputs": [],
   "source": [
    "data = [] # will temporarily hold each reactor's data\n",
    "N_reactor = -1 # keeps track of which reactor we are parsing\n",
    "with open(\"mult_reactors.txt\",'r') as f:\n",
    "  for lines in f:\n",
    "    fields = lines.split() # the file is space delimitted so this breaks up the lines into words\n",
    "\n",
    "    # FIND OUT WHAT WAS HAPPENING BEFORE THE ERROR\n",
    "    print(fields)\n",
    "\n",
    "    # Identify start of new reactor data\n",
    "    if fields[0] == \"Time(min)\":\n",
    "      N_reactor += 1\n",
    "\n",
    "    # Get the numbers\n",
    "    try:\n",
    "      data += [[float(fields[0]),float(fields[1])]]\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    # For diagnostic purposes\n",
    "    if N_reactor == 1:\n",
    "      break\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yce8pzMT6yzE"
   },
   "source": [
    "The printout is long. This is because the parser worked for a long time before encountering an error. Looking at the last printed statement before the error, we see an empty list (`[]`). Inspecting the file, we would see that there is an empty line between the reactors. Now that we see it, we can easily deal with this by skipping empty lines. Let's try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1581791983920,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "S-Dy1HDt7H2_",
    "outputId": "e9ff4445-8017-4b33-b59a-12e6e774d4e7"
   },
   "outputs": [],
   "source": [
    "data = [] # will temporarily hold each reactor's data\n",
    "N_reactor = -1 # keeps track of which reactor we are parsing\n",
    "with open(\"mult_reactors.txt\",'r') as f:\n",
    "  for lines in f:\n",
    "    fields = lines.split() # the file is space delimitted so this breaks up the lines into words\n",
    "\n",
    "    # Skip empty\n",
    "    if len(fields) == 0:\n",
    "      continue\n",
    "\n",
    "    # Identify start of new reactor data\n",
    "    if fields[0] == \"Time(min)\":\n",
    "      N_reactor += 1\n",
    "\n",
    "    # Get the numbers\n",
    "    try:\n",
    "      data += [[float(fields[0]),float(fields[1])]]\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    # For diagnostic purposes\n",
    "    if N_reactor == 1:\n",
    "      break\n",
    "print(\"length of data: {}\".format(len(data)))\n",
    "print(\"data[0]: {}\".format(data[0]))\n",
    "print(\"data[-1]: {}\".format(data[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QgQ-ZbWJ7k9_"
   },
   "source": [
    "Skipping empty lines has now solved out problem. The code executes with error through the first reactor, and we have successfuly saved all of its data to `data`. \n",
    "\n",
    "Before parsing the next reactor, we need to put the first reactor's data somewhere. Specifically, from the problem we know what we should save it as an array within a dictionary. Let's add this functionality before trying to parse the rest of the reactors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1581792001456,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "HpD6tL9Z8I_o",
    "outputId": "f292330f-f4a4-41f5-ed05-8c5cac1d96b9"
   },
   "outputs": [],
   "source": [
    "data = [] # will temporarily hold each reactor's data\n",
    "N_reactor = -1 # keeps track of which reactor we are parsing\n",
    "reactors = {} # dictionary for holding each reactor's data as an array\n",
    "with open(\"mult_reactors.txt\",'r') as f:\n",
    "  for lines in f:\n",
    "    fields = lines.split() # the file is space delimitted so this breaks up the lines into words\n",
    "\n",
    "    # Skip empty\n",
    "    if len(fields) == 0:\n",
    "      continue\n",
    "\n",
    "    # Identify start of new reactor data\n",
    "    if fields[0] == \"Time(min)\":\n",
    "      reactors[N_reactor] = np.array(data)\n",
    "      N_reactor += 1\n",
    "\n",
    "    # Get the numbers\n",
    "    try:\n",
    "      data += [[float(fields[0]),float(fields[1])]]\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    # For diagnostic purposes\n",
    "    if N_reactor == 1:\n",
    "      break\n",
    "print(\"reactors.keys(): {}\".format(reactors.keys()))\n",
    "print(\"lengths: {}\".format([ len(reactors[i]) for i in reactors.keys() ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D6pTEHNd9JA6"
   },
   "source": [
    "To check our work we might have printed out the whole `reactors` dictionary and we would have seen an issue. To save space I've just printed out the `keys()` and lengths of each array in `reactors`. The issue is that we have two arrays saved, with keys `-1` and `0` respectively, and the first one is empty. What has happened? Take a minute and think about it before moving on. \n",
    "\n",
    "The issue is that the first time that we encounter `\"Time(min)\"` is at the top of the file, <i>before</i> we have parsed any reactor data. This first encounter with `\"Time(min)\"` needs to be skipped. An easy way to do this is to only save the `data` if it is non-empty: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1581792031260,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "-aAllCIo96tT",
    "outputId": "27819b82-c24f-463b-ec89-1c496b6d737e"
   },
   "outputs": [],
   "source": [
    "data = [] # will temporarily hold each reactor's data\n",
    "N_reactor = -1 # keeps track of which reactor we are parsing\n",
    "reactors = {} # dictionary for holding each reactor's data as an array\n",
    "with open(\"mult_reactors.txt\",'r') as f:\n",
    "  for lines in f:\n",
    "    fields = lines.split() # the file is space delimitted so this breaks up the lines into words\n",
    "\n",
    "    # Skip empty\n",
    "    if len(fields) == 0:\n",
    "      continue\n",
    "\n",
    "    # Identify start of new reactor data\n",
    "    if fields[0] == \"Time(min)\":\n",
    "\n",
    "      # Save if non-empty\n",
    "      if data:\n",
    "        reactors[N_reactor] = np.array(data)\n",
    "      N_reactor += 1\n",
    "\n",
    "    # Get the numbers\n",
    "    try:\n",
    "      data += [[float(fields[0]),float(fields[1])]]\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    # For diagnostic purposes\n",
    "    if N_reactor == 1:\n",
    "      break\n",
    "print(\"reactors.keys(): {}\".format(reactors.keys()))\n",
    "print(\"lengths: {}\".format([ len(reactors[i]) for i in reactors.keys() ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmLfCA2YFY2k"
   },
   "source": [
    "With this change, we are now successfully parsing the first reactor's data and assigning it to the dictionary as an array. \n",
    "\n",
    "We've done almost all of the work. The code as written should work on the rest of the reactors, with two modifications. But first let's just test it to see what it does when we let it loose on the rest of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1581792047326,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "MJ95qQyyFzeJ",
    "outputId": "02b36bbe-68a8-451d-843a-d63ab4abdb09"
   },
   "outputs": [],
   "source": [
    "data = [] # will temporarily hold each reactor's data\n",
    "N_reactor = -1 # keeps track of which reactor we are parsing\n",
    "reactors = {} # dictionary for holding each reactor's data as an array\n",
    "with open(\"mult_reactors.txt\",'r') as f:\n",
    "  for lines in f:\n",
    "    fields = lines.split() # the file is space delimitted so this breaks up the lines into words\n",
    "\n",
    "    # Skip empty\n",
    "    if len(fields) == 0:\n",
    "      continue\n",
    "\n",
    "    # Identify start of new reactor data\n",
    "    if fields[0] == \"Time(min)\":\n",
    "\n",
    "      # Save if non-empty\n",
    "      if data:\n",
    "        reactors[N_reactor] = np.array(data)\n",
    "      N_reactor += 1\n",
    "\n",
    "    # Get the numbers\n",
    "    try:\n",
    "      data += [[float(fields[0]),float(fields[1])]]\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    #\n",
    "    # DELETED THE DIAGNOSTIC BREAK STATEMENT\n",
    "    #\n",
    "print(\"reactors.keys(): {}\".format(reactors.keys()))\n",
    "print(\"lengths: {}\".format([ len(reactors[i]) for i in reactors.keys() ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7AXlwdWHF_Vi"
   },
   "source": [
    "There are no formal errors, but we can see two problems with the output. First, we see that the amount of data for each reactor is growing, but if we inspect the file we see that it should be constant. Can you see why this is happening?\n",
    "\n",
    "The problem is that we aren't resetting the `data` list between reactors. So the previous reactors data is still there when we start parsing the next. We can correct this by reinitializing the `data` list when we save the reactor data to the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1581792068088,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "Xqgb3KhGGcom",
    "outputId": "5e7ecc0f-2142-4d6f-fdac-a9f98460a29c"
   },
   "outputs": [],
   "source": [
    "data = [] # will temporarily hold each reactor's data\n",
    "N_reactor = -1 # keeps track of which reactor we are parsing\n",
    "reactors = {} # dictionary for holding each reactor's data as an array\n",
    "with open(\"mult_reactors.txt\",'r') as f:\n",
    "  for lines in f:\n",
    "    fields = lines.split() # the file is space delimitted so this breaks up the lines into words\n",
    "\n",
    "    # Skip empty\n",
    "    if len(fields) == 0:\n",
    "      continue\n",
    "\n",
    "    # Identify start of new reactor data\n",
    "    if fields[0] == \"Time(min)\":\n",
    "\n",
    "      # Save if non-empty\n",
    "      if data:\n",
    "        reactors[N_reactor] = np.array(data)\n",
    "        data = [] # reinitialize data after we save it\n",
    "      N_reactor += 1\n",
    "\n",
    "    # Get the numbers\n",
    "    try:\n",
    "      data += [[float(fields[0]),float(fields[1])]]\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "print(\"reactors.keys(): {}\".format(reactors.keys()))\n",
    "print(\"lengths: {}\".format([ len(reactors[i]) for i in reactors.keys() ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TMFES_RCGvmH"
   },
   "source": [
    "Reinitializing `data` after saving each reactor corrects our problem. The second problem is with the number of reactors. If we inspect the file we see that there are 10 reactors, but our final dictionary only has data for 9. What's the problem?\n",
    "\n",
    "The last reactor never gets saved because it isn't followed by a `\"Time(min)\"` header. This is a common issue with parsers with chained data. The last one won't get saved because the file just ends. We can correct this by saving `data` to the dictionary after the loop breaks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1581791524005,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": "11084403397391204350"
     },
     "user_tz": 300
    },
    "id": "ertnIpbvHWlK",
    "outputId": "afcb98b3-5ee0-40f4-fad0-c0cc4c1aa53a"
   },
   "outputs": [],
   "source": [
    "data = [] # will temporarily hold each reactor's data\n",
    "N_reactor = -1 # keeps track of which reactor we are parsing\n",
    "reactors = {} # dictionary for holding each reactor's data as an array\n",
    "with open(\"mult_reactors.txt\",'r') as f:\n",
    "  for lines in f:\n",
    "    fields = lines.split() # the file is space delimitted so this breaks up the lines into words\n",
    "\n",
    "    # Skip empty\n",
    "    if len(fields) == 0:\n",
    "      continue\n",
    "\n",
    "    # Identify start of new reactor data\n",
    "    if fields[0] == \"Time(min)\":\n",
    "\n",
    "      # Save if non-empty\n",
    "      if data:\n",
    "        reactors[N_reactor] = np.array(data)\n",
    "        data = [] # reinitialize data after we save it\n",
    "      N_reactor += 1\n",
    "\n",
    "    # Get the numbers\n",
    "    try:\n",
    "      data += [[float(fields[0]),float(fields[1])]]\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "# Save the last reactor\n",
    "reactors[N_reactor] = data\n",
    "\n",
    "print(\"reactors.keys(): {}\".format(reactors.keys()))\n",
    "print(\"lengths: {}\".format([ len(reactors[i]) for i in reactors.keys() ]))\n",
    "print(\"reactors[9][-1]: {}\".format(reactors[9][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5W73zm8_00ez"
   },
   "source": [
    "We now have a working solution for our problem. \n",
    "\n",
    "Review the final program and think about explaining it to someone just starting on the problem. If you try to explain it in the order it is written, there are several things here that are difficult to explain. \n",
    "\n",
    "For example, we initialize `data=[]` and `reactors={}` at the beginning. It isn't obvious that we will need both, the first for temporarily holding each reactor's data, and the second for storing the final data. But during iterative development we converged on this solution. Likewise, it isn't obvious that `if len(fields) == 0:` is the first thing that we would need to check about the line. We added this because we encountered an error while testing a version of the program without it. Another example is the `if data:` statement. We added this because we needed to skip saving the data during the first encounter with the header, but it would be difficult to explain to someone that hadn't gone through the iterative process with us. \n",
    "\n",
    "A lot of programming is asynchronous like this. Reading the final solution from start to finish requires explanations about things that happen later. This is why it is VERY DIFFICULT to write a multi-step function or for loop correctly on the first try. We are used to thinking sequentially. To develop your programming intuitition, you need to break problems down and iteratively build up the behavior you need. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "iterative_development.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CHE597",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
